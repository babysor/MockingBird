## å®æ—¶è¯­éŸ³å…‹éš† - ä¸­æ–‡/æ™®é€šè¯
![mockingbird](https://user-images.githubusercontent.com/12797292/131216767-6eb251d6-14fc-4951-8324-2722f0cd4c63.jpg)

[![MIT License](https://img.shields.io/badge/license-MIT-blue.svg?style=flat)](http://choosealicense.com/licenses/mit/)

### [English](README.md)  | ä¸­æ–‡

### [DEMO VIDEO](https://www.bilibili.com/video/BV1sA411P7wM/)

## ç‰¹æ€§
ğŸŒ **ä¸­æ–‡** æ”¯æŒæ™®é€šè¯å¹¶ä½¿ç”¨å¤šç§ä¸­æ–‡æ•°æ®é›†è¿›è¡Œæµ‹è¯•ï¼šadatatang_200zh, magicdata, aishell3ï¼Œ biaobeiï¼ŒMozillaCommonVoice ç­‰

ğŸ¤© **PyTorch** é€‚ç”¨äº pytorchï¼Œå·²åœ¨ 1.9.0 ç‰ˆæœ¬ï¼ˆæœ€æ–°äº 2021 å¹´ 8 æœˆï¼‰ä¸­æµ‹è¯•ï¼ŒGPU Tesla T4 å’Œ GTX 2060

ğŸŒ **Windows + Linux** å¯åœ¨ Windows æ“ä½œç³»ç»Ÿå’Œ linux æ“ä½œç³»ç»Ÿä¸­è¿è¡Œï¼ˆè‹¹æœç³»ç»ŸM1ç‰ˆä¹Ÿæœ‰ç¤¾åŒºæˆåŠŸè¿è¡Œæ¡ˆä¾‹ï¼‰

ğŸ¤© **Easy & Awesome** ä»…éœ€ä¸‹è½½æˆ–æ–°è®­ç»ƒåˆæˆå™¨ï¼ˆsynthesizerï¼‰å°±æœ‰è‰¯å¥½æ•ˆæœï¼Œå¤ç”¨é¢„è®­ç»ƒçš„ç¼–ç å™¨/å£°ç å™¨ï¼Œæˆ–å®æ—¶çš„HiFi-GANä½œä¸ºvocoder

## å¿«é€Ÿå¼€å§‹
> 0è®­ç»ƒæ–°æ‰‹å‹å¥½ç‰ˆå¯ä»¥å‚è€ƒ [Quick Start (Newbie)](https://github.com/babysor/Realtime-Voice-Clone-Chinese/wiki/Quick-Start-(Newbie))

### 1. å®‰è£…è¦æ±‚
> æŒ‰ç…§åŸå§‹å­˜å‚¨åº“æµ‹è¯•æ‚¨æ˜¯å¦å·²å‡†å¤‡å¥½æ‰€æœ‰ç¯å¢ƒã€‚
**Python 3.7 æˆ–æ›´é«˜ç‰ˆæœ¬** éœ€è¦è¿è¡Œå·¥å…·ç®±ã€‚

* å®‰è£… [PyTorch](https://pytorch.org/get-started/locally/)ã€‚
> å¦‚æœåœ¨ç”¨ pip æ–¹å¼å®‰è£…çš„æ—¶å€™å‡ºç° `ERROR: Could not find a version that satisfies the requirement torch==1.9.0+cu102 (from versions: 0.1.2, 0.1.2.post1, 0.1.2.post2)` è¿™ä¸ªé”™è¯¯å¯èƒ½æ˜¯ python ç‰ˆæœ¬è¿‡ä½ï¼Œ3.9 å¯ä»¥å®‰è£…æˆåŠŸ
* å®‰è£… [ffmpeg](https://ffmpeg.org/download.html#get-packages)ã€‚
* è¿è¡Œ`pip install -r requirements.txt` æ¥å®‰è£…å‰©ä½™çš„å¿…è¦åŒ…ã€‚
* å®‰è£… webrtcvad ç”¨ `pip install webrtcvad-wheels`ã€‚

### 2. ä½¿ç”¨æ•°æ®é›†è®­ç»ƒåˆæˆå™¨
* ä¸‹è½½ æ•°æ®é›†å¹¶è§£å‹ï¼šç¡®ä¿æ‚¨å¯ä»¥è®¿é—® *train* æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶ï¼ˆå¦‚.wavï¼‰
* è¿›è¡ŒéŸ³é¢‘å’Œæ¢…å°”é¢‘è°±å›¾é¢„å¤„ç†ï¼š
`python pre.py <datasets_root>`
å¯ä»¥ä¼ å…¥å‚æ•° --dataset `{dataset}` æ”¯æŒ adatatang_200zh, magicdata, aishell3
> å‡å¦‚ä½ ä¸‹è½½çš„ `aidatatang_200zh`æ–‡ä»¶æ”¾åœ¨Dç›˜ï¼Œ`train`æ–‡ä»¶è·¯å¾„ä¸º `D:\data\aidatatang_200zh\corpus\train` , ä½ çš„`datasets_root`å°±æ˜¯ `D:\data\`

>å‡å¦‚ç™¼ç”Ÿ `é é¢æ–‡ä»¶å¤ªå°ï¼Œç„¡æ³•å®Œæˆæ“ä½œ`ï¼Œè«‹åƒè€ƒé€™ç¯‡[æ–‡ç« ](https://blog.csdn.net/qq_17755303/article/details/112564030)ï¼Œå°‡è™›æ“¬å…§å­˜æ›´æ”¹ç‚º100G(102400)ï¼Œä¾‹å¦‚:æ¡£æ¡ˆæ”¾ç½®Dæ§½å°±æ›´æ”¹Dæ§½çš„è™šæ‹Ÿå†…å­˜

* è®­ç»ƒåˆæˆå™¨ï¼š
`python synthesizer_train.py mandarin <datasets_root>/SV2TTS/synthesizer`

* å½“æ‚¨åœ¨è®­ç»ƒæ–‡ä»¶å¤¹ *synthesizer/saved_models/* ä¸­çœ‹åˆ°æ³¨æ„çº¿æ˜¾ç¤ºå’ŒæŸå¤±æ»¡è¶³æ‚¨çš„éœ€è¦æ—¶ï¼Œè¯·è½¬åˆ°ä¸‹ä¸€æ­¥ã€‚
> ä»…ä¾›å‚è€ƒï¼Œæˆ‘çš„æ³¨æ„åŠ›æ˜¯åœ¨ 18k æ­¥ä¹‹åå‡ºç°çš„ï¼Œå¹¶ä¸”åœ¨ 50k æ­¥ä¹‹åæŸå¤±å˜å¾—ä½äº 0.4
![attention_step_20500_sample_1](https://user-images.githubusercontent.com/7423248/128587252-f669f05a-f411-4811-8784-222156ea5e9d.png)
![step-135500-mel-spectrogram_sample_1](https://user-images.githubusercontent.com/7423248/128587255-4945faa0-5517-46ea-b173-928eff999330.png)

### 2.2 ä½¿ç”¨é¢„å…ˆè®­ç»ƒå¥½çš„åˆæˆå™¨
> å®åœ¨æ²¡æœ‰è®¾å¤‡æˆ–è€…ä¸æƒ³æ…¢æ…¢è°ƒè¯•ï¼Œå¯ä»¥ä½¿ç”¨ç½‘å‹è´¡çŒ®çš„æ¨¡å‹(æ¬¢è¿æŒç»­åˆ†äº«):

| ä½œè€… | ä¸‹è½½é“¾æ¥ | æ•ˆæœé¢„è§ˆ | ä¿¡æ¯ |
| --- | ----------- | ----- | ----- |
|@FawenYo | https://drive.google.com/file/d/1H-YGOUHpmqKxJ9FRc6vAjPuqQki24UbC/view?usp=sharing [ç™¾åº¦ç›˜é“¾æ¥](https://pan.baidu.com/s/1vSYXO4wsLyjnF3Unl-Xoxg) æå–ç ï¼š1024  | [input](https://github.com/babysor/MockingBird/wiki/audio/self_test.mp3) [output](https://github.com/babysor/MockingBird/wiki/audio/export.wav) | 200k steps å°æ¹¾å£éŸ³
|@miven| https://pan.baidu.com/s/1PI-hM3sn5wbeChRryX-RCQ æå–ç ï¼š2021 | https://www.bilibili.com/video/BV1uh411B7AD/ | 150k steps æ—§ç‰ˆéœ€æ ¹æ®[issue](https://github.com/babysor/MockingBird/issues/37)ä¿®å¤

### 2.3 è®­ç»ƒå£°ç å™¨ (Optional)
* é¢„å¤„ç†æ•°æ®:
`python vocoder_preprocess.py <datasets_root>`

* è®­ç»ƒå£°ç å™¨:
`python vocoder_train.py mandarin <datasets_root>`

### 3. å¯åŠ¨å·¥å…·ç®±
ç„¶åæ‚¨å¯ä»¥å°è¯•ä½¿ç”¨å·¥å…·ç®±ï¼š
`python demo_toolbox.py -d <datasets_root>`

> Good newsğŸ¤©: å¯ç›´æ¥ä½¿ç”¨ä¸­æ–‡

## Release Note
2021.9.8 æ–°å¢Hifi-GAN Vocoderæ”¯æŒ

## å¼•ç”¨åŠè®ºæ–‡
> è¯¥åº“ä¸€å¼€å§‹ä»ä»…æ”¯æŒè‹±è¯­çš„[Real-Time-Voice-Cloning](https://github.com/CorentinJ/Real-Time-Voice-Cloning) åˆ†å‰å‡ºæ¥çš„ï¼Œé¸£è°¢ä½œè€…ã€‚

| URL | Designation | æ ‡é¢˜ | å®ç°æºç  |
| --- | ----------- | ----- | --------------------- |
| [2010.05646](https://arxiv.org/abs/2010.05646) | HiFi-GAN (vocoder)| Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis | æœ¬ä»£ç åº“ |
|[**1806.04558**](https://arxiv.org/pdf/1806.04558.pdf) | **SV2TTS** | **Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis** | This repo |
|[1802.08435](https://arxiv.org/pdf/1802.08435.pdf) | WaveRNN (vocoder) | Efficient Neural Audio Synthesis | [fatchord/WaveRNN](https://github.com/fatchord/WaveRNN) |
|[1703.10135](https://arxiv.org/pdf/1703.10135.pdf) | Tacotron (synthesizer) | Tacotron: Towards End-to-End Speech Synthesis | [fatchord/WaveRNN](https://github.com/fatchord/WaveRNN)
|[1710.10467](https://arxiv.org/pdf/1710.10467.pdf) | GE2E (encoder)| Generalized End-To-End Loss for Speaker Verification | æœ¬ä»£ç åº“ |

## å¸¸è¦‹å•é¡Œ(FQ&A)
1.æ•¸æ“šé›†å“ªè£¡ä¸‹è¼‰?

[adatatang_200zh](http://www.openslr.org/62/)ã€[magicdata](http://www.openslr.org/68/)ã€[aishell3](http://www.openslr.org/93/)
> è§£å£“ adatatang_200zh å¾Œï¼Œé‚„éœ€å°‡ `aidatatang_200zh\corpus\train`ä¸‹çš„æª”æ¡ˆå…¨é¸è§£å£“ç¸®

2.`<datasets_root>`æ˜¯ä»€éº¼æ„æ€?

å‡å¦‚æ•¸æ“šé›†å­˜æ”¾åœ¨ `D:\data\adatatang_200zh`ï¼Œé‚£éº¼ `<datasets_root>`å°±æ˜¯ `D:\data`

3.è¨“ç·´æ¨¡å‹é¡¯å­˜ä¸è¶³

è¨“ç·´åˆæˆå™¨æ™‚ï¼šå°‡ `synthesizer/hparams.py`ä¸­çš„batch_sizeåƒæ•¸èª¿å°
```
//èª¿æ•´å‰
tts_schedule = [(2,  1e-3,  20_000,  12),   # Progressive training schedule
                (2,  5e-4,  40_000,  12),   # (r, lr, step, batch_size)
                (2,  2e-4,  80_000,  12),   #
                (2,  1e-4, 160_000,  12),   # r = reduction factor (# of mel frames
                (2,  3e-5, 320_000,  12),   #     synthesized for each decoder iteration)
                (2,  1e-5, 640_000,  12)],  # lr = learning rate
//èª¿æ•´å¾Œ
tts_schedule = [(2,  1e-3,  20_000,  8),   # Progressive training schedule
                (2,  5e-4,  40_000,  8),   # (r, lr, step, batch_size)
                (2,  2e-4,  80_000,  8),   #
                (2,  1e-4, 160_000,  8),   # r = reduction factor (# of mel frames
                (2,  3e-5, 320_000,  8),   #     synthesized for each decoder iteration)
                (2,  1e-5, 640_000,  8)],  # lr = learning rate
```

è²ç¢¼å™¨-é è™•ç†æ•¸æ“šé›†æ™‚ï¼šå°‡ `synthesizer/hparams.py`ä¸­çš„batch_sizeåƒæ•¸èª¿å°
```
//èª¿æ•´å‰
### Data Preprocessing
        max_mel_frames = 900,
        rescale = True,
        rescaling_max = 0.9,
        synthesis_batch_size = 16,                  # For vocoder preprocessing and inference.
//èª¿æ•´å¾Œ
### Data Preprocessing
        max_mel_frames = 900,
        rescale = True,
        rescaling_max = 0.9,
        synthesis_batch_size = 8,                  # For vocoder preprocessing and inference.
```

è²ç¢¼å™¨-è¨“ç·´è²ç¢¼å™¨æ™‚ï¼šå°‡ `vocoder/wavernn/hparams.py`ä¸­çš„batch_sizeåƒæ•¸èª¿å°
```
//èª¿æ•´å‰
# Training
voc_batch_size = 100
voc_lr = 1e-4
voc_gen_at_checkpoint = 5
voc_pad = 2

//èª¿æ•´å¾Œ
# Training
voc_batch_size = 6
voc_lr = 1e-4
voc_gen_at_checkpoint = 5
voc_pad =2
```

* 4.ç¢°åˆ°`RuntimeError: Error(s) in loading state_dict for Tacotron: size mismatch for encoder.embedding.weight: copying a param with shape torch.Size([70, 512]) from checkpoint, the shape in current model is torch.Size([75, 512]).`

è«‹åƒç…§ issue #37